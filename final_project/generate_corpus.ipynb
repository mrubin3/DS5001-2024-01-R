{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6807c0e5-3d4f-426d-bd06-c9bd85ac1878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "from glob import glob\n",
    "config = configparser.ConfigParser()\n",
    "import sys\n",
    "config.read(\"../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "local_lib = config['DEFAULT']['local_lib']\n",
    "sys.path.append(local_lib)\n",
    "from textparser import TextParser\n",
    "\n",
    "OHCO = ['para_num', 'sent_num', 'token_num']\n",
    "source_files = f'{data_home}/sotu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7899f6bc-b68e-406d-b155-463f04a02252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>year</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\179...</td>\n",
       "      <td>1790</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>washington</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\179...</td>\n",
       "      <td>1790</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washington</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\179...</td>\n",
       "      <td>1791</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>washington</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\179...</td>\n",
       "      <td>1792</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>washington</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\179...</td>\n",
       "      <td>1793</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>trump</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\202...</td>\n",
       "      <td>2020</td>\n",
       "      <td>REP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>biden</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\202...</td>\n",
       "      <td>2021</td>\n",
       "      <td>DEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>biden</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\202...</td>\n",
       "      <td>2022</td>\n",
       "      <td>DEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>biden</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\202...</td>\n",
       "      <td>2023</td>\n",
       "      <td>DEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>biden</td>\n",
       "      <td>C:/Users/patso/Documents/DS5001//data/sotu\\202...</td>\n",
       "      <td>2024</td>\n",
       "      <td>DEM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            president                                   source_file_path  \\\n",
       "speech_id                                                                  \n",
       "1          washington  C:/Users/patso/Documents/DS5001//data/sotu\\179...   \n",
       "2          washington  C:/Users/patso/Documents/DS5001//data/sotu\\179...   \n",
       "3          washington  C:/Users/patso/Documents/DS5001//data/sotu\\179...   \n",
       "4          washington  C:/Users/patso/Documents/DS5001//data/sotu\\179...   \n",
       "5          washington  C:/Users/patso/Documents/DS5001//data/sotu\\179...   \n",
       "...               ...                                                ...   \n",
       "110             trump  C:/Users/patso/Documents/DS5001//data/sotu\\202...   \n",
       "111             biden  C:/Users/patso/Documents/DS5001//data/sotu\\202...   \n",
       "112             biden  C:/Users/patso/Documents/DS5001//data/sotu\\202...   \n",
       "113             biden  C:/Users/patso/Documents/DS5001//data/sotu\\202...   \n",
       "114             biden  C:/Users/patso/Documents/DS5001//data/sotu\\202...   \n",
       "\n",
       "           year party  \n",
       "speech_id              \n",
       "1          1790   IND  \n",
       "2          1790   IND  \n",
       "3          1791   IND  \n",
       "4          1792   IND  \n",
       "5          1793   IND  \n",
       "...         ...   ...  \n",
       "110        2020   REP  \n",
       "111        2021   DEM  \n",
       "112        2022   DEM  \n",
       "113        2023   DEM  \n",
       "114        2024   DEM  \n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB = pd.read_csv('LIB.csv', sep='|').set_index('speech_id')\n",
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef5a3f9-2a02-47e8-8d30-c9ecc8caad0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing washington\n",
      "Tokenizing adams\n",
      "Tokenizing adams\n",
      "Tokenizing adams\n",
      "Tokenizing adams\n",
      "Tokenizing wilson\n",
      "Tokenizing wilson\n",
      "Tokenizing wilson\n",
      "Tokenizing wilson\n",
      "Tokenizing wilson\n",
      "Tokenizing wilson\n",
      "Tokenizing harding\n",
      "Tokenizing harding\n",
      "Tokenizing coolidge\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing roosevelt\n",
      "Tokenizing truman\n",
      "Tokenizing truman\n",
      "Tokenizing truman\n",
      "Tokenizing truman\n",
      "Tokenizing truman\n",
      "Tokenizing truman\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing eisenhower\n",
      "Tokenizing kennedy\n",
      "Tokenizing kennedy\n",
      "Tokenizing kennedy\n",
      "Tokenizing johnson\n",
      "Tokenizing johnson\n",
      "Tokenizing johnson\n",
      "Tokenizing johnson\n",
      "Tokenizing johnson\n",
      "Tokenizing johnson\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing nixon\n",
      "Tokenizing ford\n",
      "Tokenizing ford\n",
      "Tokenizing ford\n",
      "Tokenizing carter\n",
      "Tokenizing carter\n",
      "Tokenizing carter\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing reagan\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing clinton\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing bush\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing obama\n",
      "Tokenizing trump\n",
      "Tokenizing trump\n",
      "Tokenizing trump\n",
      "Tokenizing trump\n",
      "Tokenizing biden\n",
      "Tokenizing biden\n",
      "Tokenizing biden\n",
      "Tokenizing biden\n"
     ]
    }
   ],
   "source": [
    "clip_pats = [r\"\\*\\*\\*\\s*START OF\", r\"\\*\\*\\*\\s*END OF\"]\n",
    "\n",
    "speeches = []\n",
    "for speech in LIB.index:\n",
    "    print(\"Tokenizing\", LIB.loc[speech].president)\n",
    "    src_file_path = LIB.loc[speech]['source_file_path']\n",
    "    text = TextParser(src_file_path, ohco_pats=[('chap', r\"\\*\\*\\*\\s*START OF\",'m')],\n",
    "                      clip_pats=clip_pats, use_nltk=True)\n",
    "    text.verbose = False\n",
    "    text.strip_hyphens = True\n",
    "    text.strip_whitespace = True\n",
    "    text.import_source().parse_tokens()\n",
    "    text.TOKENS['speech_id'] = speech\n",
    "    text.TOKENS = text.TOKENS.reset_index().set_index(['speech_id']+text.OHCO)\n",
    "    speeches.append(text.TOKENS)\n",
    "CORPUS = pd.concat(speeches).reset_index().drop(columns=['chap_id']).set_index(['speech_id']+OHCO).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391ceb82-fdf0-44ce-ba84-945b8836d08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Fellow, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Fellow</td>\n",
       "      <td>fellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Citizens, NNPS)</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>Citizens</td>\n",
       "      <td>citizens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(of, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Senate, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Senate</td>\n",
       "      <td>senate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">114</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">267</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>(you,, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>you,</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(thank, VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>thank</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(you,, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>you,</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(thank, VB)</td>\n",
       "      <td>VB</td>\n",
       "      <td>thank</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(you., NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>you.</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543926 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pos_tuple   pos token_str  \\\n",
       "speech_id para_num sent_num token_num                                     \n",
       "1         0        0        0             (Fellow, NNP)   NNP    Fellow   \n",
       "                            1          (Citizens, NNPS)  NNPS  Citizens   \n",
       "                            2                  (of, IN)    IN        of   \n",
       "                            3                 (the, DT)    DT       the   \n",
       "                            4             (Senate, NNP)   NNP    Senate   \n",
       "...                                                 ...   ...       ...   \n",
       "114       267      1        1               (you,, PRP)   PRP      you,   \n",
       "                            2              (thank, VBD)   VBD     thank   \n",
       "                            3               (you,, PRP)   PRP      you,   \n",
       "                            4               (thank, VB)    VB     thank   \n",
       "                            5                (you., NN)    NN      you.   \n",
       "\n",
       "                                       term_str  \n",
       "speech_id para_num sent_num token_num            \n",
       "1         0        0        0            fellow  \n",
       "                            1          citizens  \n",
       "                            2                of  \n",
       "                            3               the  \n",
       "                            4            senate  \n",
       "...                                         ...  \n",
       "114       267      1        1               you  \n",
       "                            2             thank  \n",
       "                            3               you  \n",
       "                            4             thank  \n",
       "                            5               you  \n",
       "\n",
       "[543926 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9491f597-861c-404d-ba18-deff4fb66f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CORPUS.to_csv('CORPUS.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7cd17-de23-4951-a676-712ddcde9534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
